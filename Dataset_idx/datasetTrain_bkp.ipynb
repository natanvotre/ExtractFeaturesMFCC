{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trata as palavras-chave dos arquivos de audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrega a tabela que faz referencia aos arquivos de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "from scipy.io.wavfile import read as wavread\n",
    "from scipy.io.wavfile import write as wavwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usrp/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>recOOV</th>\n",
       "      <th>file</th>\n",
       "      <th>idx_abre</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MISC</td>\n",
       "      <td>100</td>\n",
       "      <td>Estevan_3.wav</td>\n",
       "      <td>[4730 76320 131880 180000 212000]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MISC</td>\n",
       "      <td>100</td>\n",
       "      <td>Marina_1.wav</td>\n",
       "      <td>[29450 106430 165400 214060 330190]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MISC</td>\n",
       "      <td>100</td>\n",
       "      <td>Marina_4.wav</td>\n",
       "      <td>[12170 82450 138570 180800 218120 280850 347250]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MISC</td>\n",
       "      <td>100</td>\n",
       "      <td>Marina_6.wav</td>\n",
       "      <td>[25130 57970 125860 199900 239820 277720 33808...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MISC</td>\n",
       "      <td>100</td>\n",
       "      <td>Natan_1.wav</td>\n",
       "      <td>[25670 107110 162700 208770 332250]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type  recOOV           file  \\\n",
       "0           0  MISC     100  Estevan_3.wav   \n",
       "1           1  MISC     100   Marina_1.wav   \n",
       "2           2  MISC     100   Marina_4.wav   \n",
       "3           3  MISC     100   Marina_6.wav   \n",
       "4           4  MISC     100    Natan_1.wav   \n",
       "\n",
       "                                            idx_abre  Unnamed: 5  \n",
       "0                  [4730 76320 131880 180000 212000]         NaN  \n",
       "1                [29450 106430 165400 214060 330190]         NaN  \n",
       "2   [12170 82450 138570 180800 218120 280850 347250]         NaN  \n",
       "3  [25130 57970 125860 199900 239820 277720 33808...         NaN  \n",
       "4                [25670 107110 162700 208770 332250]         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset_idx.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formata as colunas de indexação em formatos de lista "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['idx_abre']\n",
    "iAbre = {}\n",
    "for i in range(len(x)):\n",
    "    p = x[i]\n",
    "    p = p.replace('[','')\n",
    "    p = p.replace(']','')\n",
    "    \n",
    "    p = p.split(' ')\n",
    "#     print(p)\n",
    "    if p[0] != '':\n",
    "        iAbre[i] = list(map(int, p))\n",
    "    else:\n",
    "        iAbre[i] = list(map(int,[-1e9])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4730, 76320, 131880, 180000, 212000]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iAbre[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição das constantes\n",
    "\n",
    "Com índices de cada arquivo de audio para cada palavra-chave, temos o centro de cada _frame_ que conterá as respectivas palavras-chave. \n",
    "\n",
    "Então, agora é preciso configurar todos os parâmetros para extração de _feature_ para a entrada. \n",
    "Isso ocorre pois estes parâmetros alterarão os tamanhos de _frames_ que serão agora coletados para cada _keyword_   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 8000 # taxa de amostragem dos arquivos de audio\n",
    "\n",
    "n_fft= 512   # tamanho da FFT para extração dos MFCCs\n",
    "hop_length=0 # pulo entre cada frame\n",
    "n_mels= 50   # numero de filtros MEL\n",
    "n_mfcc= 15   # numero de coeficientes MFFC\n",
    "ofs_mfcc=2   # offset dado para não utilizar os primeiros coeficientes MFCC      \n",
    "\n",
    "fmin=100    # frequencia mínima do MFCC\n",
    "fmax=4000   # frequencia máxima do MFCC\n",
    "\n",
    "n_frames_MFCC = 10 # numero de frames MFCC que será usado para o reconhecimento.\n",
    "\n",
    "frame_len = (n_frames_MFCC-1)*n_fft # tamanho do frame recortado para cada entrada\n",
    "frame_lenD2 = int(frame_len/2) # tamanho do frame dividido por 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4608, 2304)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_len, frame_lenD2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração das _Features_ que contém a palavra-chave\n",
    "\n",
    "Agora que todas as constantes necessárias ja foram declaradas, é extraído de cada arquivo de áudio os _frames_ contendo a palavras-chave, conforme indexado por `iAbre[i]`.\n",
    "\n",
    "Após extraído tais _frames_, é realizado o cálculo do MFCC para a extração das _features_ de cada _frame_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameMFCC = {}\n",
    "kwFeat = {}\n",
    "for i in range(len(df['file'])):\n",
    "    wavstr = df['file'][i]  # extrai a string contendo o nome do arquivo de audio\n",
    "    [_, data_file] = wavread(wavstr) # Lê todo o arquivo de audio\n",
    "\n",
    "    data_file = data_file/32767 # normaliza as amostras do  áudio para o range [-1,1]\n",
    "    N = data_file.shape[0]      # indica o tamanho do arquivo\n",
    "\n",
    "#     # quando necessário é plotado o áudio do arquivo \n",
    "#     t = np.linspace(0, N/fs, N)\n",
    "#     plt.plot(t, data_file)\n",
    "    for j in range(len(iAbre[i])): # para cada audio, retira os frames kw e as features\n",
    "        if iAbre[i][j] < 0:\n",
    "            break\n",
    "        \n",
    "        frameSample = data_file[iAbre[i][j]-frame_lenD2:iAbre[i][j]+frame_lenD2]\n",
    "        MFCCsample = librosa.feature.mfcc(y=frameSample, sr=fs, fmin=fmin, fmax=fmax, \n",
    "                                             n_mfcc=n_mfcc, n_mels=n_mels, n_fft=n_fft)\n",
    "\n",
    "        frameMFCC[j] = MFCCsample[ofs_mfcc:]\n",
    "    \n",
    "    kwFeat[i] = frameMFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of keyword inputs: 106\n",
      "number of keyword test inputs: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMwAAAD8CAYAAAA7WEtfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADWhJREFUeJzt3W+MXPV1xvHn2dld7/q/sY0JtgtOS2kQakTqphCkVApBhYaGqu0LaIloWok3TUKiSCm0kfKmLyo1ShOpUSpESCOBIKpxVRTRBJSQVpVaK2Bcg7FTKKT28s8OxBgvtnfXe/pix2hxbbxnz/XMXev7kSzvzN77u2d25pl7Z+785jgiBGBuBvpdALCQEBgggcAACQQGSCAwQAKBARIIDJBAYIAEAgMkDPZyY8MDIzHaWVYbZGioXMfxRZ3i+uUS5AY+YDFduxmSpPes/nl5jNUDU6X19xxZWa5h+ue1x8XEm69r6ui4z7RcTwMz2lmmq1b+XmmM2HhBuY7Dm2qhPfiL9Ufq4NHyEDq6uj7GF//wO+Ux/mjZa6X1r95Ze0xI0rEH15XW37P1b+e0HIdkQAKBARIIDJBQCozt62z/xPZztu9oqiigreYdGNsdSV+XdL2kyyTdbPuypgoD2qiyh/mgpOci4vmImJD0gKQbmykLaKdKYNZL2jfr8lj3OuCcVTkPc6qTPP/vdJzt2yTdJkkjA0sLmwP6r7KHGZO0cdblDZJeOnmhiLgrIjZHxObhgZHC5oD+qwTmx5Iusb3J9rCkmyQ91ExZQDvN+5AsIqZsf0rS9yV1JN0TEbsaqwxoodJnySLiYUkPN1QL0Hqc6QcSCAyQQGCAhJ7Oh5EH5JHaW8ux5/lyGcsP1ebUdCbWlmt4dXN9Itz0cH0W2hf/tT4X5a9eqt2W0Vfqt+PoujPO/XpX03O8CexhgAQCAyQQGCCBwAAJBAZIIDBAAoEBEggMkEBggAQCAyQQGCCBwAAJBAZIIDBAAoEBEggMkNDTCWRTK4a1/7cuKo5SXV9avP94af03N9YbKnm6PITUwBjLn6lPZBt5vTYBbHJJuQQNvlVbf673B3sYIIHAAAkEBkggMEBCpaHSRtuP2d5te5ft25ssDGijyrtkU5I+HxHbbS+T9ITtRyPimYZqA1pn3nuYiHg5IrZ3f35T0m7RUAnnuEZew9i+WNIVkrad4ne32X7c9uNTR8ab2BzQN+XA2F4q6UFJn42IQyf/fnZDpcHRBs5QAX1UbTs+pJmw3BcRW5spCWivyrtklvRNSbsj4ivNlQS0V2UPc7WkT0j6iO0d3X+/3VBdQCtVWvb9u07dSRk4Z3GmH0ggMEBCT+fDdI6FVrxwrJebPCsWvVF/nhl+s95EKAbqR8Tn7TxYHmPv9StL6x9bU5/YM7K/+LeY4+rsYYAEAgMkEBgggcAACQQGSCAwQAKBARIIDJBAYIAEAgMkEBgggcAACQQGSCAwQAKBARIIDJDQ0wlkPjKh4af3lcaIo0frdQzXmgh1Hnu9XMP47/9GeYzlTx0ojzG1Zml5jLU7Jkvrv7Wu/jBc8T9HSuuPHZ7bJDb2MEACgQESCAyQQGCAhCa+jLxj+0nb322iIKDNmtjD3K6Z3jDAOa/67f0bJH1M0t3NlAO0W3UP81VJX5BU/yY2YAGotLu4QdL+iHjiDMu93YFsYrp2cgnot2q7i4/b/qmkBzTT9uLekxea3YFseGC0sDmg/ypNYe+MiA0RcbGkmyT9MCJuaawyoIU4DwMkNPLhy4j4kaQfNTEW0GbsYYAEAgMkEBggoacTyKZWLtKB3/ml0hhH1ta7bk2sqHX/WvNf9e5hE8vqt2P82nXlMY6tKg+hRcUmZhPL6jWMHKxNCpwenNv9wR4GSCAwQAKBARIIDJBAYIAEAgMkEBgggcAACQQGSCAwQAKBARIIDJBAYIAEAgMkEBgggcAACb2dQDYqvfb+2uSrTgPfBTh4tDZ5a6LetEtH19QnkK189nh5jPP2TJXHOD5Se94dP7/+MBw+WLsdA3P8U7KHARIIDJBAYICEaruLlba32N5je7ftq5oqDGij6qutr0n6XkT8ge1hSYsbqAlorXkHxvZySR+W9MeSFBETkiaaKQtop8oh2XslHZD0rW6Py7ttL2moLqCVKoEZlPQBSd+IiCskjUu64+SFZjdUOn54vLA5oP8qgRmTNBYR27qXt2gmQO8wu6FSZyk7ICxslYZKr0jaZ/vS7lXXSHqmkaqAlqq+S/ZpSfd13yF7XtIn6yUB7VUKTETskLS5oVqA1uNMP5BAYIAEAgMk9HQ+zKLXpvXL9/b/XEwUp6KMb2zgE0CuP1cNHpkujzGxov4Q6BTrmFxanxs0tbhTWj/meHewhwESCAyQQGCABAIDJBAYIIHAAAkEBkggMEACgQESCAyQQGCABAIDJBAYIIHAAAkEBkggMEBCTyeQxZB1ZN1oaYzORH3S1PgFQ6X1R1+rNyEaPlyfNDW5pP58d+ii2sQrSVr1bK1JVhPG19UeytODc7s/2MMACQQGSCAwQAKBARKqHcg+Z3uX7adt3297pKnCgDaad2Bsr5f0GUmbI+JySR1JNzVVGNBG1UOyQUmjtgc1067vpXpJQHtV2l28KOnLkvZKelnSGxHxSFOFAW1UOSRbJelGSZskXShpie1bTrHc2x3IJif6/62XQEXlkOyjkl6IiAMRMSlpq6QPnbzQ7A5kQ8N0IMPCVgnMXklX2l5s25rpQLa7mbKAdqq8htmmmb6W2yU91R3rrobqAlqp2oHsS5K+1FAtQOtxph9IIDBAAoEBEno6gez4sHV4fW3C0vHhesnDh2oTnsbPr9cweKw+6WpgsjyEfuEf95XHOPRrF5bWXzZ2vFzDdPEu8RznJbKHARIIDJBAYIAEAgMkEBgggcAACQQGSCAwQAKBARIIDJBAYIAEAgMkEBgggcAACQQGSCAwQEJPJ5ANjk9r7fbDpTEGDta/DNCTtQ5i4+9bV64hOvUOZNND9THe2Fyb/CXVO6FNLKvfjuV7a/epp+c2oY89DJBAYIAEAgMknDEwtu+xvd/207OuO8/2o7af7f6/6uyWCbTDXPYw/yDpupOuu0PSDyLiEkk/6F4GznlnDExE/Juk10+6+kZJ3+7+/G1Jv9twXUArzfc1zLqIeFmSuv+f31xJQHud9Rf972ioNEVDJSxs8w3Mq7bfI0nd//efbsF3NFQapKESFrb5BuYhSbd2f75V0j83Uw7QbnN5W/l+Sf8h6VLbY7b/VNJfS7rW9rOSru1eBs55Z/wsWUTcfJpfXdNwLUDrcaYfSCAwQAKBARJ6Oh9masmAXv31ZaUxYrC2viRNLq2tP9jA6aShw/WGSm9dWJ9H0jlaHkJLX5xjN6LTGP1Z/W9xZHWtUdf04Nz+luxhgAQCAyQQGCCBwAAJBAZIIDBAAoEBEggMkEBggAQCAyQQGCCBwAAJBAZIIDBAAoEBEggMkNDbhkpHprVm51ulMaYX1SYKSdLR1UOl9aOBp5np+s3Q0r0N1DFcH2P8gtofZM3OY+UaOpO1SWydY3Nbnz0MkEBggAQCAyQQGCBhvh3I/sb2Hts7bf+T7ZVnt0ygHebbgexRSZdHxK9K+m9JdzZcF9BK8+pAFhGPRMSJxuj/KWnDWagNaJ0mXsP8iaR/Od0vZzdUmpikoRIWtlJgbP+lpClJ951umdkNlYaHaKiEhW3eZ/pt3yrpBknXRET9uz6BBWBegbF9naQ/l/SbEVH7rAuwgMy3A9nfSVom6VHbO2z//VmuE2iF+XYg++ZZqAVoPc70AwkEBkggMECCe/mOsO0Dkv73XRZZI+lnPSrn3bShjjbUILWjjl7UcFFErD3TQj0NzJnYfjwiNlNHO2poSx1tqOEEDsmABAIDJLQtMHf1u4CuNtTRhhqkdtTRhhoktew1DNB2bdvDAK3WmsDYvs72T2w/Z/uOPmx/o+3HbO+2vcv27b2u4aR6OraftP3dPm1/pe0t3anou21f1ac6Pte9P562fb/tkX7UcUIrAmO7I+nrkq6XdJmkm21f1uMypiR9PiLeJ+lKSX/Whxpmu13S7j5u/2uSvhcRvyLp/f2oxfZ6SZ+RtDkiLpfUkXRTr+uYrRWBkfRBSc9FxPMRMSHpAUk39rKAiHg5IrZ3f35TMw+Q9b2s4QTbGyR9TNLdfdr+ckkfVvdDthExEREH+1GLZj4gPGp7UNJiSS/1qQ5J7QnMekn7Zl0eU58erJJk+2JJV0ja1qcSvirpC5Jq3386f++VdEDSt7qHhXfb7vl02Yh4UdKXJe2V9LKkNyLikV7XMVtbAuNTXNeXt+9sL5X0oKTPRsShPmz/Bkn7I+KJXm97lkFJH5D0jYi4QtK4pH68rlylmSONTZIulLTE9i29rmO2tgRmTNLGWZc3qA+7XttDmgnLfRGxtdfb77pa0sdt/1Qzh6YfsX1vj2sYkzQWESf2sFs0E6Be+6ikFyLiQERMStoq6UN9qONtbQnMjyVdYnuT7WHNvLB7qJcF2LZmjtl3R8RXernt2SLizojYEBEXa+bv8MOI6OmzakS8Immf7Uu7V10j6Zle1tC1V9KVthd3759r1N83Qnrb7uJ0ImLK9qckfV8z74TcExG7elzG1ZI+Iekp2zu61/1FRDzc4zra4tOS7us+gT0v6ZO9LiAittneImm7Zt7FfFJ9PuvPmX4goS2HZMCCQGCABAIDJBAYIIHAAAkEBkggMEACgQES/g91r0c3OztpGgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lenKW_1 = 0\n",
    "for i in range(len(df['file'])):\n",
    "    if df['file'][i].find('Vitor') == -1:\n",
    "        for j in range(len(iAbre[i])):\n",
    "            if iAbre[i][j] < 0:\n",
    "                break\n",
    "            \n",
    "            lenKW_1=lenKW_1+1\n",
    "\n",
    "lenKW_1_test = 0\n",
    "for i in range(len(df['file'])):\n",
    "    if df['file'][i].find('Vitor') != -1:\n",
    "        for j in range(len(iAbre[i])):\n",
    "            if iAbre[i][j] < 0:\n",
    "                break\n",
    "            \n",
    "            lenKW_1_test=lenKW_1_test+1\n",
    "            \n",
    "print('number of keyword inputs:',lenKW_1)\n",
    "print('number of keyword test inputs:',lenKW_1_test)\n",
    "imgplot = plt.imshow(kwFeat[0][7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(int,['100']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração dos indices e das _Features_ _Out of Vocabulary_\n",
    "\n",
    "Para treinar a rede, é necessário utilizar exemplos do que não é as palavras-chave, chamadas de _Out Of Vocabulary Word_ (OOV _words_).\n",
    "Então, é indexado aleatoriamente trechos dos áudios contendo palavras OOV, para posteriormente a extração das _features_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOV_lenght = 100 # gera OOV_length OutOfVoc frames por audio\n",
    "OOV_lenght = list(map(int,df['recOOV'])) # gera OOV_length OutOfVoc frames por audio\n",
    "iOOV = {}\n",
    "# iOOVk = np.zeros(OOV_lenght)\n",
    "\n",
    "for i in range(len(df['file'])):\n",
    "    wavstr = df['file'][i]  # extrai a string contendo o nome do arquivo de audio\n",
    "    [_, data_file] = wavread(wavstr) # Lê todo o arquivo de audio\n",
    "\n",
    "    data_file = data_file/32767 # normaliza as amostras do  áudio para o range [-1,1]\n",
    "    N = data_file.shape[0]      # indica o tamanho do arquivo\n",
    "#     print(N)\n",
    "    \n",
    "    iOOVk = np.zeros(OOV_lenght[i])\n",
    "\n",
    "    for k in range(OOV_lenght[i]):\n",
    "        # tenta adquirir indices que indicam frames com Out Of Voc words\n",
    "        # de forma aleatoria\n",
    "        goodId = False\n",
    "        while goodId == False:\n",
    "            idx = np.random.randint(N-frame_len)+frame_lenD2 # gera numero aleatorio\n",
    "            goodId = True\n",
    "            for j in range(len(iAbre[i])): # analisa o indice criado com os indices das kw\n",
    "                if abs(idx-iAbre[i][j]) < frame_len:\n",
    "                    goodId = False\n",
    "        \n",
    "        iOOVk[k] = idx\n",
    "            \n",
    "    iOOV[i] = iOOVk.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([377878,  37907, 225683, 266144, 101531, 268794,  18636, 171478,\n",
       "       250939,   7300, 430656, 309263, 139551, 138435,  95420,  71968,\n",
       "       221922,  44497, 135134,  50867, 283265,  56453, 233088, 192572,\n",
       "       196053, 354433, 308042,  23508, 268079, 209363, 346490, 309843,\n",
       "        44354, 181016, 181742, 415339, 151058, 262394, 246575, 296328,\n",
       "       349715, 338908,  83153, 301627, 270334, 400672, 357610, 246127,\n",
       "       302811, 292559,  72205, 278913, 424262, 279775, 189093, 450156,\n",
       "       180323, 383465, 188691, 139581, 340651, 400713, 138035, 403847,\n",
       "       412358, 101643, 315824,  52243, 444335, 317020, 241313, 399080,\n",
       "       399750, 139172, 119023, 190849, 263221, 412250,  83482, 431773,\n",
       "        68995, 390136, 345452, 340633, 197571,  43423, 433565,   3599,\n",
       "       262960, 128113, 180207, 245263, 316151, 267382,  69136, 371870,\n",
       "       131517, 442064, 406742,  38157])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iOOV[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gera arquivo de audio contendo os trechos OOV para analise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=2\n",
    "wavstr = df['file'][i]  # extrai a string contendo o nome do arquivo de audio\n",
    "[_, data_file] = wavread(wavstr) # Lê todo o arquivo de audio\n",
    "\n",
    "data_file = data_file/32767 # normaliza as amostras do  áudio para o range [-1,1]\n",
    "N = data_file.shape[0]      # indica o tamanho do arquivo\n",
    "\n",
    "#     # quando necessário é plotado o áudio do arquivo \n",
    "#     t = np.linspace(0, N/fs, N)\n",
    "#     plt.plot(t, data_file)\n",
    "\n",
    "frameSample = np.zeros((frame_len,len(iOOV[i])))\n",
    "for j in range(len(iOOV[i])): # para cada audio, retira os frames kw e as features\n",
    "    frameSample[:,j] = data_file[iOOV[i][j]-frame_lenD2:iOOV[i][j]+frame_lenD2]\n",
    "\n",
    "frameSample = frameSample.T.reshape(-1)\n",
    "wavwrite('framesOOV.wav', fs, frameSample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extração das Features OOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameMFCC = {}\n",
    "oovFeat = {}\n",
    "for i in range(len(df['file'])):\n",
    "    wavstr = df['file'][i]  # extrai a string contendo o nome do arquivo de audio\n",
    "    [_, data_file] = wavread(wavstr) # Lê todo o arquivo de audio\n",
    "\n",
    "    data_file = data_file/32767 # normaliza as amostras do  áudio para o range [-1,1]\n",
    "    N = data_file.shape[0]      # indica o tamanho do arquivo\n",
    "\n",
    "#     # quando necessário é plotado o áudio do arquivo \n",
    "#     t = np.linspace(0, N/fs, N)\n",
    "#     plt.plot(t, data_file)\n",
    "    for j in range(len(iOOV[i])): # para cada audio, retira os frames kw e as features\n",
    "        frameSample = data_file[iOOV[i][j]-frame_lenD2:iOOV[i][j]+frame_lenD2]\n",
    "        \n",
    "        MFCCsample = librosa.feature.mfcc(y=frameSample, sr=fs, fmin=fmin, fmax=fmax, \n",
    "                                             n_mfcc=n_mfcc, n_mels=n_mels, n_fft=n_fft)\n",
    "        \n",
    "        frameMFCC[j] = MFCCsample[ofs_mfcc:]\n",
    "    \n",
    "    oovFeat[i] = frameMFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of out-of-voc inputs: 2140\n",
      "number of out-of-voc test inputs: 320\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lenOOV = 0\n",
    "for i in range(len(df['file'])):\n",
    "    if df['file'][i].find('Vitor') == -1:\n",
    "        for j in range(len(iOOV[i])):\n",
    "            lenOOV=lenOOV+1\n",
    "\n",
    "lenOOVtest = 0\n",
    "for i in range(len(df['file'])):\n",
    "    if df['file'][i].find('Vitor') != -1:\n",
    "        for j in range(len(iOOV[i])):\n",
    "            lenOOVtest=lenOOVtest+1\n",
    "            \n",
    "print('number of out-of-voc inputs:', lenOOV)\n",
    "print('number of out-of-voc test inputs:', lenOOVtest)\n",
    "\n",
    "imgplot = plt.imshow(oovFeat[0][99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparando o _Data Array_\n",
    "\n",
    "Neste ponto é gerado _arrays_ para dados de treinamento e de teste.\n",
    "\n",
    "Para isso, é atribuido _arrays_ de elementos OOV e elementos KW, concatenados, embaralhados, e separados em dados de treinamento e de teste.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(x, y, p=0.2): # funcao para embaralhar e separar os dados em treinamento e teste\n",
    "    shapeInX = x.shape\n",
    "    shapeInY = y.shape\n",
    "    datax = x.reshape(shapeInX[0],-1)\n",
    "    \n",
    "    data = np.concatenate((datax, y), axis=1)\n",
    "    # random.randint(0, int(x.shape[0]*(1-p)))\n",
    "    xScrambled = np.random.permutation(data)\n",
    "    nLines = xScrambled.shape[0]\n",
    "\n",
    "    data_train = xScrambled[0:int(round(nLines*(1-p))), :]\n",
    "    data_test = xScrambled[int(round(nLines*(1-p))):, :]\n",
    "#     print(nLines)\n",
    "#     print(data_train.shape)\n",
    "    \n",
    "    shape_train = np.asarray(shapeInX)\n",
    "    shape_train[0] = data_train.shape[0]\n",
    "    x_train = data_train[:,:data_train.shape[1]-shapeInY[1]].reshape(tuple(shape_train))\n",
    "    y_train = data_train[:,[data_train.shape[1]-shapeInY[1]]]\n",
    "    \n",
    "    \n",
    "    shape_test = np.asarray(shapeInX)\n",
    "    shape_test[0] = data_test.shape[0]\n",
    "    x_test = data_test[:,:data_test.shape[1]-shapeInY[1]].reshape(tuple(shape_test))\n",
    "    y_test = data_test[:,data_test.shape[1]-shapeInY[1]:]\n",
    "    \n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword Abre Array Shape: (106, 13, 10, 1)\n",
      "Out Of Voc Array Shape: (2140, 13, 10, 1)\n",
      "\n",
      "Concatenate Array Shape: (2246, 13, 10, 1)\n",
      "\n",
      "Train data shape: (2021, 13, 10, 1)\n",
      "Test data shape: (225, 13, 10, 1)\n",
      "\n",
      "counting of Truth keywords in Test Data: 9\n",
      "counting of OOV words in Test Data: 216\n"
     ]
    }
   ],
   "source": [
    "# gera os arrays OOV e KW, com suas respectivas labels\n",
    "x_OOV = np.zeros((lenOOV, oovFeat[0][0].shape[0], oovFeat[0][0].shape[1],1))\n",
    "x_KW_1 = np.zeros((lenKW_1, oovFeat[0][0].shape[0], oovFeat[0][0].shape[1],1))\n",
    "\n",
    "x_OOV_test = np.zeros((lenOOVtest, oovFeat[0][0].shape[0], oovFeat[0][0].shape[1],1))\n",
    "x_KW_1_test = np.zeros((lenKW_1_test, oovFeat[0][0].shape[0], oovFeat[0][0].shape[1],1))\n",
    "\n",
    "# y_OOV = np.concatenate((np.ones((lenOOV, 1)), np.zeros((lenOOV,  1))), axis=1)\n",
    "# y_KW_1 = np.concatenate((np.zeros((lenKW_1,  1)), np.ones((lenKW_1, 1))), axis=1)\n",
    "y_OOV = np.zeros((lenOOV,  1))\n",
    "y_KW_1 = np.ones((lenKW_1, 1))\n",
    "\n",
    "y_OOV_test = np.zeros((lenOOVtest,  1))\n",
    "y_KW_1_test = np.ones((lenKW_1_test, 1))\n",
    "\n",
    "k=0\n",
    "m=0\n",
    "for i in range(len(df['file'])):\n",
    "    if df['file'][i].find('Vitor') == -1:\n",
    "        for j in range(len(iOOV[i])): \n",
    "            x_OOV[k,:,:,0] = oovFeat[i][j]\n",
    "            k=k+1\n",
    "    else:\n",
    "        for j in range(len(iOOV[i])): \n",
    "            x_OOV_test[m,:,:,0] = oovFeat[i][j]\n",
    "            m=m+1\n",
    "        \n",
    "\n",
    "k=0\n",
    "m=0\n",
    "for i in range(len(df['file'])):\n",
    "    if df['file'][i].find('Vitor') == -1:\n",
    "        for j in range(len(iAbre[i])):\n",
    "            if iAbre[i][j] < 0:\n",
    "                break\n",
    "            x_KW_1[k,:,:,0] = kwFeat[i][j]\n",
    "            k=k+1\n",
    "    else:\n",
    "        for j in range(len(iAbre[i])): \n",
    "            if iAbre[i][j] < 0:\n",
    "                break\n",
    "                \n",
    "            x_KW_1_test[m,:,:,0] = kwFeat[i][j]\n",
    "            m=m+1\n",
    "\n",
    "print('Keyword Abre Array Shape:', x_KW_1.shape)\n",
    "print('Out Of Voc Array Shape:', x_OOV.shape)\n",
    "        \n",
    "x = np.concatenate((x_OOV, x_KW_1), axis=0)\n",
    "y = np.concatenate((y_OOV, y_KW_1), axis=0)\n",
    "\n",
    "print('\\nConcatenate Array Shape:', x.shape)\n",
    "\n",
    "# print(x.shape)\n",
    "# print(x_OOV.shape)\n",
    "# print(x_KW_1.shape)\n",
    "# print(y.shape)\n",
    "# print(y_OOV.shape)\n",
    "# print(y_KW_1.shape)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = splitData(x, y, p=0.1)\n",
    "print('\\nTrain data shape:', x_train.shape)\n",
    "print('Test data shape:', x_test.shape)\n",
    "\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(y_test.shape)\n",
    "\n",
    "print('\\ncounting of Truth keywords in Test Data:', list(y_test[:]).count(1))\n",
    "print('counting of OOV words in Test Data:', list(y_test[:]).count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepros_feat = [fs,# = 16000 # taxa de amostragem dos arquivos de audio\n",
    "                n_fft,#= 512   # tamanho da FFT para extração dos MFCCs\n",
    "                hop_length,#=0 # pulo entre cada frame\n",
    "                n_mels,#= 50   # numero de filtros MEL\n",
    "                n_mfcc,#= 16   # numero de coeficientes MFCC\n",
    "                ofs_mfcc,#=2   # offset dado para não utilizar os primeiros coeficientes MFCC      \n",
    "                fmin,#=100    # frequencia mínima do MFCC\n",
    "                fmax,#=4000   # frequencia máxima do MFCC\n",
    "                n_frames_MFCC,# = 10 # numero de frames MFCC que será usado para o reconhecimento.]\n",
    "                frame_len, #= (n_frames_MFCC-1)*n_fft # tamanho do frame recortado para cada entrada\n",
    "                frame_lenD2 #= int(frame_len/2) # tamanho do frame dividido por 2\n",
    "                ]\n",
    "\n",
    "Rede = {}\n",
    "Rede['preFeat'] = prepros_feat\n",
    "Rede['x_train'] = x_train\n",
    "Rede['y_train'] = y_train\n",
    "Rede['x_test'] = x_test\n",
    "Rede['y_test'] = y_test\n",
    "\n",
    "# Rede['Model'] = model\n",
    "# Rede['History'] = history\n",
    "# Rede = [prepros_feat, [x_train, y_train, x_test, y_test]]\n",
    "\n",
    "# pickle.dump( Rede, open( 'RedeTeste1.pickle', 'wb' ) )\n",
    "np.save(\"DataSet1.npy\", Rede)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rede = np.load(\"DataSet1.npy\").item()\n",
    "\n",
    "# prepros_feat \t= Rede['preFeat']  \n",
    "# x_train \t\t= Rede['x_train']\n",
    "# y_train\t\t\t= Rede['y_train'] \n",
    "# x_test \t\t\t= Rede['x_test'] \n",
    "# y_test \t\t\t= Rede['y_test']\n",
    "prepros_feat \t= Rede['preFeat']  \n",
    "x_train \t\t= Rede['x_train']\n",
    "y_train\t\t\t= Rede['y_train'] \n",
    "x_test \t\t\t= Rede['x_test'] \n",
    "y_test \t\t\t= Rede['y_test']\n",
    "\n",
    "fs = prepros_feat[0] # = 16000 # taxa de amostragem dos arquivos de audio\n",
    "n_fft = prepros_feat[1] #= 512   # tamanho da FFT para extração dos MFCCs\n",
    "hop_length = prepros_feat[2] #=0 # pulo entre cada frame\n",
    "n_mels = prepros_feat[3] #= 50   # numero de filtros MEL\n",
    "n_mfcc = prepros_feat[4] #= 16   # numero de coeficientes MFCC\n",
    "ofs_mfcc = prepros_feat[5] #=2   # offset dado para não utilizar os primeiros coeficientes MFCC      \n",
    "fmin = prepros_feat[6] #=100    # frequencia mínima do MFCC\n",
    "fmax = prepros_feat[7] #=4000   # frequencia máxima do MFCC\n",
    "n_frames_MFCC = prepros_feat[8] # = 10 # numero de frames MFCC que será usado para o reconhecimento.]\n",
    "frame_len = prepros_feat[9]\n",
    "frame_lenD2 = prepros_feat[10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 10, 1)\n",
      "Epoch 1/40\n",
      "2021/2021 [==============================] - 0s 236us/step - loss: 5.2503 - acc: 0.3909\n",
      "Epoch 2/40\n",
      "2021/2021 [==============================] - 0s 77us/step - loss: 1.2021 - acc: 0.7709\n",
      "Epoch 3/40\n",
      "2021/2021 [==============================] - 0s 74us/step - loss: 0.5497 - acc: 0.8956\n",
      "Epoch 4/40\n",
      "2021/2021 [==============================] - 0s 84us/step - loss: 0.4510 - acc: 0.9080\n",
      "Epoch 5/40\n",
      "2021/2021 [==============================] - 0s 74us/step - loss: 0.3493 - acc: 0.9070\n",
      "Epoch 6/40\n",
      "2021/2021 [==============================] - 0s 74us/step - loss: 0.2642 - acc: 0.9278\n",
      "Epoch 7/40\n",
      "2021/2021 [==============================] - 0s 78us/step - loss: 0.2140 - acc: 0.9451\n",
      "Epoch 8/40\n",
      "2021/2021 [==============================] - 0s 70us/step - loss: 0.1822 - acc: 0.9515\n",
      "Epoch 9/40\n",
      "2021/2021 [==============================] - 0s 70us/step - loss: 0.1604 - acc: 0.9634\n",
      "Epoch 10/40\n",
      "2021/2021 [==============================] - 0s 67us/step - loss: 0.1446 - acc: 0.9688\n",
      "Epoch 11/40\n",
      "2021/2021 [==============================] - 0s 72us/step - loss: 0.1315 - acc: 0.9743\n",
      "Epoch 12/40\n",
      "2021/2021 [==============================] - 0s 69us/step - loss: 0.1204 - acc: 0.9772\n",
      "Epoch 13/40\n",
      "2021/2021 [==============================] - 0s 75us/step - loss: 0.1106 - acc: 0.9777\n",
      "Epoch 14/40\n",
      "2021/2021 [==============================] - 0s 71us/step - loss: 0.1021 - acc: 0.9762\n",
      "Epoch 15/40\n",
      "2021/2021 [==============================] - 0s 79us/step - loss: 0.0938 - acc: 0.9777\n",
      "Epoch 16/40\n",
      "2021/2021 [==============================] - 0s 72us/step - loss: 0.0861 - acc: 0.9782\n",
      "Epoch 17/40\n",
      "2021/2021 [==============================] - 0s 73us/step - loss: 0.0788 - acc: 0.9802\n",
      "Epoch 18/40\n",
      "2021/2021 [==============================] - 0s 71us/step - loss: 0.0724 - acc: 0.9802\n",
      "Epoch 19/40\n",
      "2021/2021 [==============================] - 0s 75us/step - loss: 0.0667 - acc: 0.9822\n",
      "Epoch 20/40\n",
      "2021/2021 [==============================] - 0s 78us/step - loss: 0.0616 - acc: 0.9876\n",
      "Epoch 21/40\n",
      "2021/2021 [==============================] - 0s 74us/step - loss: 0.0576 - acc: 0.9891\n",
      "Epoch 22/40\n",
      "2021/2021 [==============================] - 0s 75us/step - loss: 0.0532 - acc: 0.9906\n",
      "Epoch 23/40\n",
      "2021/2021 [==============================] - 0s 74us/step - loss: 0.0495 - acc: 0.9921\n",
      "Epoch 24/40\n",
      "2021/2021 [==============================] - 0s 75us/step - loss: 0.0463 - acc: 0.9921\n",
      "Epoch 25/40\n",
      "2021/2021 [==============================] - 0s 73us/step - loss: 0.0435 - acc: 0.9926\n",
      "Epoch 26/40\n",
      "2021/2021 [==============================] - 0s 74us/step - loss: 0.0408 - acc: 0.9936\n",
      "Epoch 27/40\n",
      "2021/2021 [==============================] - 0s 69us/step - loss: 0.0383 - acc: 0.9946\n",
      "Epoch 28/40\n",
      "2021/2021 [==============================] - 0s 76us/step - loss: 0.0359 - acc: 0.9946\n",
      "Epoch 29/40\n",
      "2021/2021 [==============================] - 0s 79us/step - loss: 0.0342 - acc: 0.9946\n",
      "Epoch 30/40\n",
      "2021/2021 [==============================] - 0s 71us/step - loss: 0.0321 - acc: 0.9946\n",
      "Epoch 31/40\n",
      "2021/2021 [==============================] - 0s 74us/step - loss: 0.0308 - acc: 0.9946\n",
      "Epoch 32/40\n",
      "2021/2021 [==============================] - 0s 73us/step - loss: 0.0291 - acc: 0.9946\n",
      "Epoch 33/40\n",
      "2021/2021 [==============================] - 0s 71us/step - loss: 0.0276 - acc: 0.9951\n",
      "Epoch 34/40\n",
      "2021/2021 [==============================] - 0s 74us/step - loss: 0.0263 - acc: 0.9955\n",
      "Epoch 35/40\n",
      "2021/2021 [==============================] - 0s 74us/step - loss: 0.0251 - acc: 0.9960\n",
      "Epoch 36/40\n",
      "2021/2021 [==============================] - 0s 70us/step - loss: 0.0239 - acc: 0.9960\n",
      "Epoch 37/40\n",
      "2021/2021 [==============================] - 0s 72us/step - loss: 0.0228 - acc: 0.9970\n",
      "Epoch 38/40\n",
      "2021/2021 [==============================] - 0s 70us/step - loss: 0.0217 - acc: 0.9975\n",
      "Epoch 39/40\n",
      "2021/2021 [==============================] - 0s 69us/step - loss: 0.0207 - acc: 0.9975\n",
      "Epoch 40/40\n",
      "2021/2021 [==============================] - 0s 81us/step - loss: 0.0197 - acc: 0.9975\n",
      "225/225 [==============================] - 0s 207us/step\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "num_classes = 2\n",
    "\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(input_shape)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(3, kernel_size=(3, 3), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# model.add(Conv2D(4, (2, 2), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=40,\n",
    "          batch_size=128)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.016585472971200943, 1.0]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frameMFCC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "idxFile = 0\n",
    "idxSmp  = 3\n",
    "\n",
    "k=0\n",
    "for i in range(len(df['file'])):\n",
    "    for j in range(len(iAbre[i])):\n",
    "#         plt.imshow(kwFeat[i][j])\n",
    "#         plt.show()\n",
    "        k=k+1\n",
    "\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavwrite('frame.wav', fs, frame1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
