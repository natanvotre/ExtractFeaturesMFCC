{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Keyword Spotting_ usando redes convolucionais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "_Keyword Spotting_ é uma técnica de detecção de palavras chaves pré-definidas em um falas continuadas [1]. É muito utilizado no contexto de reconhecimento de fala nos _wake word systems_, tal como o \"_Ok Google!_\" dos dispositivos **Android** [2]. Neste documento, é apresentado uma solução em _Keyword Spotting_ usando redes neurais artificiais convolucionais. \n",
    "\n",
    "### _Dataset_\n",
    "\n",
    "O _dataset_ utilizado no projeto é o **_DARPA TIMIT_**, conhecido na literatura e utilizado em algumas publicações [3-5]. Este _dataset_ é dividido em locutores e por texto, onde o usuário tem acesso aos arquivos `.WAV`, à transcrição e também as indexações por palavras e por fonemas.\n",
    "\n",
    "Neste trabalho é utilizado as indexações por palavras e também os arquivos `.WAV` contidos no _dataset_.  \n",
    "\n",
    "### Divisão do _dataset_\n",
    "\n",
    "O _dataset_ é dividido em dois blocos: treinamento e teste.\n",
    "A classificação é realizda através de duas classes: palavras fora do vocabulário (**OOV**) e palavra-chave (**KW**)\n",
    "\n",
    "### _Features_\n",
    "\n",
    "Para a extração de _features_ dos trechos de áudio, correspondentes a OOV e KW, é utilizado uma matriz de **_Mel Frequency Cepstrum Coefficients_** (MFCC). Cada coluna da matriz representa uma extração MFCC de um subtrecho do trecho de áudio.\n",
    "\n",
    "Os MFCCs são extraidos a partir dos parametros:\n",
    "```python\n",
    "fs = 16000 # taxa de amostragem dos arquivos de audio\n",
    "\n",
    "n_fft= 512   # tamanho da FFT para extração dos MFCCs\n",
    "hop_length=0 # pulo entre cada frame\n",
    "n_mels= 50   # numero de filtros MEL\n",
    "n_mfcc= 15   # numero de coeficientes MFFC\n",
    "ofs_mfcc=2   # offset dado para não utilizar os primeiros coeficientes MFCC      \n",
    "\n",
    "fmin=100    # frequencia mínima do MFCC\n",
    "fmax=4000   # frequencia máxima do MFCC\n",
    "\n",
    "n_frames_MFCC = 10 # numero de frames MFCC que será usado para o reconhecimento.\n",
    "\n",
    "frame_len = (n_frames_MFCC-1)*n_fft # tamanho do frame recortado para cada entrada\n",
    "frame_lenD2 = int(frame_len/2) # tamanho do frame dividido por 2\n",
    "```\n",
    "\n",
    "Para a extração dos MFCCs, é utilizado a biblioteca ```librosa```\n",
    "```python\n",
    "import librosa```\n",
    "\n",
    "### Rede Neural\n",
    "\n",
    "O treinamento da Rede Neural é realizado utilizando a biblioteca ```keras```\n",
    "```python\n",
    "import keras```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código\n",
    "\n",
    "Na sequência é apresentado o código realizado para extração de _features_, treinamento e teste da Rede Neural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaração de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "from scipy.io.wavfile import read as wavread\n",
    "from scipy.io.wavfile import write as wavwrite\n",
    "\n",
    "import os, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usrp/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaração de _PATHs_\n",
    "\n",
    "Aqui é declarado os caminhos para que estão armazenados o _dataset_ e onde estará armazenada as _features_ de KW e OOV.\n",
    "\n",
    "Também é declarado a _keyword_ escolhida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR_TIMIT = 'TRAIN'\n",
    "TRAIN_DIR_KW = os.path.join('data','train','kw')\n",
    "TRAIN_DIR_OOV = os.path.join('data','train','oov')\n",
    "\n",
    "TEST_DIR_TIMIT = 'TEST'\n",
    "TEST_DIR_KW = os.path.join('data','test','kw')\n",
    "TEST_DIR_OOV = os.path.join('data','test','oov')\n",
    "\n",
    "# keyword escolhida\n",
    "KEYWORD = 'you'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaração de constantes MFCC\n",
    "\n",
    "Aqui são declaradas as constantes utilizadas na extração de _features_ MFCC dos trechos de áudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 16000 # taxa de amostragem dos arquivos de audio\n",
    "\n",
    "n_fft= 512   # tamanho da FFT para extração dos MFCCs\n",
    "hop_length=0 # pulo entre cada frame\n",
    "n_mels= 50   # numero de filtros MEL\n",
    "n_mfcc= 15   # numero de coeficientes MFFC\n",
    "ofs_mfcc=2   # offset dado para não utilizar os primeiros coeficientes MFCC      \n",
    "\n",
    "fmin=100    # frequencia mínima do MFCC\n",
    "fmax=4000   # frequencia máxima do MFCC\n",
    "\n",
    "n_frames_MFCC = 10 # numero de frames MFCC que será usado para o reconhecimento.\n",
    "\n",
    "frame_len = (n_frames_MFCC-1)*n_fft # tamanho do frame recortado para cada entrada\n",
    "frame_lenD2 = int(frame_len/2) # tamanho do frame dividido por 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de _features_\n",
    "\n",
    "Nesta etapa é extraido as _features_ dos exemplos de áudio do _dataset_ **DARPA TIMIT**\n",
    "\n",
    "1. Inicialmente, é gerado as pastas que serão armazenadas as _features_\n",
    "\n",
    "2. Na sequência, é percorrido, através de um ```for```, todas as pastas do _dataset_ **DARPA TIMIT**\n",
    "\n",
    "3. Posteriormente, é analisado cada arquivo _.WRD_, encontrando exemplos da _keyword_ escolhida através do parâmetro ```KEYWORD```. Em cada exemplo, é extraido dos arquivos _.WAV_ os trechos correspondentes a _keyword_ e realizada a extração dos MFCCs do exemplo.\n",
    "\n",
    "4. Agora, de forma aleatória, é escolhido ```OOV_N``` exemplos de OOV de cada arquivo de áudio.\n",
    "\n",
    "5. Finalmente, são salvas as listas que contém as _features_, as matrizes MFCC (OOV e KW), que serão utilizadas no treinamento da rede neural.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio em 1530656743.8564048\n"
     ]
    }
   ],
   "source": [
    "DIR = (TRAIN_DIR_TIMIT, TRAIN_DIR_KW, TRAIN_DIR_OOV)\n",
    "\n",
    "# se nao existe, gera as pastas\n",
    "if not os.path.isdir(DIR[1]):\n",
    "    os.makedirs(DIR[1])\n",
    "if not os.path.isdir(DIR[2]):\n",
    "    os.makedirs(DIR[2])\n",
    "\n",
    "# declara as variaveis utilizadas no laço\n",
    "start = time.time()\n",
    "print('Inicio em', start)\n",
    "wrd_list = []\n",
    "# 2. percorre por todos os arquivos de audio do dataset\n",
    "for path, dirs, files in os.walk(DIR[0]):\n",
    "    for file in files:\n",
    "        # encontra os arquivos .WRD\n",
    "        if file.endswith('WRD'):\n",
    "            # .wav\n",
    "            fullFileName = os.path.join(path, file)\n",
    "            fnameNoSuffix = os.path.splitext(fullFileName)[0]\n",
    "\n",
    "            # abre o arquvo .WRD\n",
    "            text = open(fullFileName,'r')\n",
    "            for line in text.read().splitlines():\n",
    "                word = line.split(' ')[2] # adquire a terceira palavra da linha\n",
    "                wrd_list.append(word) # armazena em uma word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i, x in enumerate(wrd_list) if x == \"blue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_MFCC_TIMIT(typeDIR='train'):\n",
    "    if typeDIR=='train':\n",
    "        DIR = (TRAIN_DIR_TIMIT, TRAIN_DIR_KW, TRAIN_DIR_OOV)\n",
    "    else:\n",
    "        DIR = (TEST_DIR_TIMIT, TEST_DIR_KW, TEST_DIR_OOV)\n",
    "    # 1.\n",
    "    # se nao existe, gera as pastas\n",
    "    if not os.path.isdir(DIR[1]):\n",
    "        os.makedirs(DIR[1])\n",
    "    if not os.path.isdir(DIR[2]):\n",
    "        os.makedirs(DIR[2])\n",
    "\n",
    "    # declara as variaveis utilizadas no laço\n",
    "    start = time.time()\n",
    "    print('Inicio em', start)\n",
    "    cnt = 0\n",
    "    wrd_list = []\n",
    "    cnt_kw = 0\n",
    "    cnt_oov = 0\n",
    "    OOV_N = 5\n",
    "    cnt_dirs = 0\n",
    "    kw_MFCC = []\n",
    "    oov_MFCC = []\n",
    "    # 2. percorre por todos os arquivos de audio do dataset\n",
    "    for path, dirs, files in os.walk(DIR[0]):\n",
    "    #     kw_MFCC = []\n",
    "    #     oov_MFCC = []\n",
    "        for file in files:\n",
    "            # encontra os arquivos .WRD\n",
    "            if file.endswith('WRD'):\n",
    "                # .wav\n",
    "                fullFileName = os.path.join(path, file)\n",
    "                fnameNoSuffix = os.path.splitext(fullFileName)[0]\n",
    "\n",
    "                [data_file, _] = librosa.load(fnameNoSuffix + '.WAV') # Lê todo o arquivo de audio\n",
    "                N = data_file.shape[0]  # indica o tamanho do arquivo\n",
    "\n",
    "                # abre o arquvo .WRD\n",
    "                text = open(fullFileName,'r')\n",
    "                have_KW = False\n",
    "                center = 1e12\n",
    "                # 3.\n",
    "                # no arquivo .WRD, le todas as linhas\n",
    "                for line in text.read().splitlines():\n",
    "                    word = line.split(' ')[2] # adquire a terceira palavra da linha\n",
    "                    wrd_list.append(word) # armazena em uma word list\n",
    "\n",
    "                    # se encontrar uma keyword\n",
    "                    if word == KEYWORD:\n",
    "                        # encontra o centro da keyword\n",
    "                        center = int((int(line.split(' ')[0]) + int(line.split(' ')[1]))/2)\n",
    "                        have_KW = True\n",
    "\n",
    "                        # verifica se os o frame está dentro dos limites do arquivo de audio\n",
    "                        # e extrai o trecho de audio contendo a KW\n",
    "                        if center < frame_lenD2:\n",
    "                            frameSample = np.concatenate((np.zeros(frame_lenD2-center), data_file[0:center+frame_lenD2]))\n",
    "                        else:\n",
    "                            frameSample = data_file[center-frame_lenD2:center+frame_lenD2]\n",
    "\n",
    "                        # extrai os MFCCs do trecho contendo a KW\n",
    "                        MFCCsample = librosa.feature.mfcc(y=frameSample, sr=fs, fmin=fmin, fmax=fmax, \n",
    "                                                             n_mfcc=n_mfcc, n_mels=n_mels, n_fft=n_fft)\n",
    "\n",
    "                        # armazena em uma lista\n",
    "                        kw_MFCC.append(MFCCsample[ofs_mfcc:])\n",
    "                        # conta o numero de trechos MFCC KW extraidos\n",
    "                        cnt_kw+=1\n",
    "\n",
    "                # 4.\n",
    "                # executa o laco OOV_N vezes \n",
    "                for p in range(OOV_N):\n",
    "                    goodId = False\n",
    "                    while goodId == False:\n",
    "                        # escolhe um indice aleatorio para centro do trecho OOV \n",
    "                        # dentro do arquivo de audio\n",
    "                        idx = np.random.randint(N-frame_len)+frame_lenD2 # gera numero aleatorio\n",
    "                        goodId = True\n",
    "\n",
    "    #                     for j in range(len(center)): # analisa o indice criado com os indices das kw\n",
    "    #                         if abs(idx-iAbre[i][j]) < frame_len:\n",
    "    #                             goodId = False\n",
    "\n",
    "                        # se bater com o trecho da KW, escolhe outro\n",
    "                        if abs(idx-center) < frame_len:\n",
    "                            goodId = False\n",
    "\n",
    "                        # extrai o trecho de audio\n",
    "                        frameSample = data_file[idx-frame_lenD2:idx+frame_lenD2]\n",
    "\n",
    "                        # extrai os MFCCs\n",
    "                        MFCCsample = librosa.feature.mfcc(y=frameSample, sr=fs, fmin=fmin, fmax=fmax, \n",
    "                                                             n_mfcc=n_mfcc, n_mels=n_mels, n_fft=n_fft)\n",
    "\n",
    "                        # salva em uma lista\n",
    "                        oov_MFCC.append(MFCCsample[ofs_mfcc:])\n",
    "\n",
    "                        # conta o numero de trechos MFCC OOV extraidos\n",
    "                        cnt_oov+=1\n",
    "\n",
    "    #             if cnt_oov > 50:\n",
    "    #                 break\n",
    "    #     if cnt_oov > 50:\n",
    "    #         break\n",
    "\n",
    "    #     cnt_dirs += 1\n",
    "    #     if cnt_dirs == 10:\n",
    "    #         break\n",
    "\n",
    "    #     if  kw_MFCC != []:\n",
    "    #         featFileName = os.path.join(DIR[1], fnameNoSuffix.split(os.sep)[-2] + '-' + fnameNoSuffix.split(os.sep)[-1] + '.npy')\n",
    "    #     #     featFileName = os.path.join(DIR[1], 'KW_MFCCs.npy')\n",
    "    #         np.save(featFileName, kw_MFCC)\n",
    "\n",
    "    #     featFileName = os.path.join(DIR[2], fnameNoSuffix.split(os.sep)[-2] + '-' + fnameNoSuffix.split(os.sep)[-1] + '.npy')\n",
    "    #     #     featFileName = os.path.join(DIR[2], 'OOV_MFCCs.npy')\n",
    "    #     np.save(featFileName, oov_MFCC)\n",
    "\n",
    "    ##### Salva os arquivos e imprimi a duração da extração dos MFCC do dataset\n",
    "\n",
    "    # featFileName = os.path.join(DIR[1], fnameNoSuffix.split(os.sep)[-2] + '-' + fnameNoSuffix.split(os.sep)[-1] + '.npy')\n",
    "    featFileName = os.path.join(DIR[1], 'KW_MFCCs.npy')\n",
    "    np.save(featFileName, kw_MFCC)\n",
    "\n",
    "    # featFileName = os.path.join(DIR[2], fnameNoSuffix.split(os.sep)[-2] + '-' + fnameNoSuffix.split(os.sep)[-1] + '.npy')\n",
    "    featFileName = os.path.join(DIR[2], 'OOV_MFCCs.npy')\n",
    "    np.save(featFileName, oov_MFCC)\n",
    "\n",
    "    fim = time.time()\n",
    "    print('Fim em', fim)\n",
    "    print('\\n{}: \\n\\nKW examples: {}\\nOOV examples: {}\\n\\nduration: {:.0f}s'.format(typeDIR, cnt_kw, cnt_oov, (time.time()-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio em 1530649091.7711096\n",
      "Fim em 1530650297.3983436\n",
      "\n",
      "train: \n",
      "\n",
      "KW examples: 274\n",
      "OOV examples: 23386\n",
      "\n",
      "duration: 1206s\n"
     ]
    }
   ],
   "source": [
    "extract_MFCC_TIMIT(typeDIR='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio em 1530648174.6324682\n",
      "Fim em 1530648642.7034981\n",
      "\n",
      "test: \n",
      "\n",
      "KW examples: 88\n",
      "OOV examples: 8492\n",
      "\n",
      "duration: 468s\n"
     ]
    }
   ],
   "source": [
    "extract_MFCC_TIMIT(typeDIR='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_MFCC = np.load(os.path.join(TRAIN_DIR_KW, 'KW_MFCCs.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov_MFCC = np.load(os.path.join(TRAIN_DIR_OOV, 'OOV_MFCCs.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplos\n",
    "\n",
    "As figuras abaixo apresentam exemplos das matrizes MFCC, as _features_, geradas na etapa anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aqui é apresentado a matriz MFCC da keyword numero 100 \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f83cc51c898>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=100\n",
    "print('\\nAqui é apresentado a matriz MFCC da keyword numero', i, '\\n\\n')\n",
    "\n",
    "plt.imshow(kw_MFCC[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aqui é apresentado a matriz MFCC da OOV numero 40 \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f83cc939f28>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=40\n",
    "print('\\nAqui é apresentado a matriz MFCC da OOV numero', i, '\\n\\n')\n",
    "\n",
    "plt.imshow(oov_MFCC[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Split Data_\n",
    "\n",
    "A função abaixo é utilizada para embaralhar e separar o conjunto de dados. \n",
    "Neste trabalho, é utilizada apenas para para embaralhar o conjunto de treinamento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(x, y, p=0.2): \n",
    "    shapeInX = x.shape\n",
    "    shapeInY = y.shape\n",
    "    datax = x.reshape(shapeInX[0],-1)\n",
    "    \n",
    "    data = np.concatenate((datax, y), axis=1)\n",
    "    # random.randint(0, int(x.shape[0]*(1-p)))\n",
    "    xScrambled = np.random.permutation(data)\n",
    "    nLines = xScrambled.shape[0]\n",
    "\n",
    "    data_train = xScrambled[0:int(round(nLines*(1-p))), :]\n",
    "    data_test = xScrambled[int(round(nLines*(1-p))):, :]\n",
    "#     print(nLines)\n",
    "#     print(data_train.shape)\n",
    "    \n",
    "    shape_train = np.asarray(shapeInX)\n",
    "    shape_train[0] = data_train.shape[0]\n",
    "    x_train = data_train[:,:data_train.shape[1]-shapeInY[1]].reshape(tuple(shape_train))\n",
    "    y_train = data_train[:,[data_train.shape[1]-shapeInY[1]]]\n",
    "    \n",
    "    \n",
    "    shape_test = np.asarray(shapeInX)\n",
    "    shape_test[0] = data_test.shape[0]\n",
    "    x_test = data_test[:,:data_test.shape[1]-shapeInY[1]].reshape(tuple(shape_test))\n",
    "    y_test = data_test[:,data_test.shape[1]-shapeInY[1]:]\n",
    "    \n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embaralha o conjunto as _features_ OOV e KW para gerar os dados de treinamento: ```(x_train, y_train)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1548, 13, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "OOV_uses = 5000\n",
    "oov_MFCC = oov_MFCC[:OOV_uses]\n",
    "\n",
    "y_OOV = np.zeros((len(oov_MFCC),  1))\n",
    "y_KW = np.ones((len(kw_MFCC),  1))\n",
    "\n",
    "(x_train, y_train), _ = splitData(\n",
    "            np.concatenate((np.array(kw_MFCC), \n",
    "                           np.array(kw_MFCC), np.array(oov_MFCC)), axis=0), \n",
    "            np.concatenate((np.array(y_KW), \n",
    "                           np.array(y_KW), np.array(y_OOV)), axis=0), p=0)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\n",
    "# print(y_train[:300])\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural Convolucional\n",
    "\n",
    "É utilizado neste trabalho uma Rede Neural Convolucional para classificar as _keywords_ e as OOVs.\n",
    "\n",
    "Em [9] é explorado o uso de _convolutional neural networks_ (CNN)\n",
    "em sistemas de _keyword spotting_. É apresentado um ganho relativo\n",
    "de 27-44% de _false reject rate_ comparado com _dense neural networks_\n",
    "(DNN). Tais comparações foram realizadas observando o número de\n",
    "parâmetros e multiplicações realizadas, mostrando que as CNNs utilizam muito menos parâmetros e multiplicações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "num_classes = 2\n",
    "\n",
    "print(input_shape)\n",
    "y_train_ce = keras.utils.to_categorical(y_train.reshape(-1), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do Modelo\n",
    "\n",
    "Abaixo é declarada a estrutura do modelo da Rede Neural que será utilizada. \n",
    "\n",
    "O Sumário do modelo da rede é apresentado na sequência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************ SUMÁRIO DA REDE ************************\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 9, 8, 7)           112       \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 6, 7, 10)          570       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 3, 3, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 2, 2, 10)          410       \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 82        \n",
      "=================================================================\n",
      "Total params: 1,174\n",
      "Trainable params: 1,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(7, kernel_size=(5, 3), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "# model.add(Conv2D(4, kernel_size=(3, 4), strides=(1, 1),\n",
    "#                  activation='relu'))\n",
    "# model.add(Conv2D(3, kernel_size=(2, 4), strides=(1, 1),\n",
    "#                  activation='relu'))\n",
    "# model.add(Conv2D(3, kernel_size=(2, 4), strides=(1, 1),\n",
    "#                  activation='relu'))\n",
    "model.add(Conv2D(10, kernel_size=(4, 2), strides=(1, 1),\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(10, kernel_size=(2, 2), strides=(1, 1),\n",
    "                 activation='relu'))\n",
    "# model.add(Conv2D(2, kernel_size=(2, 4), strides=(1, 1),\n",
    "#                  activation='relu',\n",
    "#                  input_shape=input_shape))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# model.add(Conv2D(4, (2, 2), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('************************ SUMÁRIO DA REDE ************************\\n\\n')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1393 samples, validate on 155 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.3567 - acc: 0.9390 - val_loss: 0.6757 - val_acc: 0.8774\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.3400 - acc: 0.9246 - val_loss: 0.4159 - val_acc: 0.9290\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.2557 - acc: 0.9304 - val_loss: 0.3501 - val_acc: 0.9226\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.1308 - acc: 0.9627 - val_loss: 0.2792 - val_acc: 0.9419\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.1060 - acc: 0.9821 - val_loss: 0.2480 - val_acc: 0.9484\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0738 - acc: 0.9864 - val_loss: 0.1945 - val_acc: 0.9742\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0572 - acc: 0.9914 - val_loss: 0.1593 - val_acc: 0.9871\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0492 - acc: 0.9943 - val_loss: 0.1399 - val_acc: 0.9871\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0434 - acc: 0.9971 - val_loss: 0.1420 - val_acc: 0.9871\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0401 - acc: 0.9971 - val_loss: 0.1433 - val_acc: 0.9871\n",
      "\n",
      "Neural Network Trained! \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_weight = {0: 1.,\n",
    "                1: 1.}\n",
    "\n",
    "history = model.fit(x_train, y_train_ce,\n",
    "          validation_split=0.1,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          class_weight=class_weight,\n",
    "          verbose=2,\n",
    "                   )\n",
    "print('\\nNeural Network Trained! \\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analise do desempenho \n",
    "\n",
    "Neste etapa, é analisado o desempenho da rede neural utilizando o conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_MFCC2 = np.load(os.path.join(TEST_DIR_KW, 'KW_MFCCs.npy'))\n",
    "oov_MFCC2 = np.load(os.path.join(TEST_DIR_OOV, 'OOV_MFCCs.npy'))\n",
    "\n",
    "y_OOV = np.zeros((len(oov_MFCC2),  1))\n",
    "y_KW = np.ones((len(kw_MFCC2),  1))\n",
    "\n",
    "x_KW = np.array(kw_MFCC2)\n",
    "x_OOV = np.array(oov_MFCC2)\n",
    "\n",
    "x_KW = x_KW.reshape(x_KW.shape[0],x_KW.shape[1],x_KW.shape[2],1)\n",
    "x_OOV = x_OOV.reshape(x_OOV.shape[0],x_OOV.shape[1],x_OOV.shape[2],1)\n",
    "\n",
    "(x_test, y_test), _ = splitData(\n",
    "            np.concatenate((x_KW, x_OOV), axis=0), \n",
    "            np.concatenate((y_KW, y_OOV), axis=0), p=0)\n",
    "\n",
    "x_test = x_test\n",
    "\n",
    "y_test_ce = keras.utils.to_categorical(y_test.reshape(-1), num_classes)\n",
    "y_OOV_ce  = keras.utils.to_categorical(y_OOV.reshape(-1), num_classes)\n",
    "y_KW_ce   = keras.utils.to_categorical(y_KW.reshape(-1), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 145us/step\n",
      "8492/8492 [==============================] - 1s 107us/step\n",
      "\n",
      "Score True of model with test KW dataset: 28.40909118002111 %\n",
      "\n",
      "Score False of model with test OOV dataset: 81.30004710596349 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scoreTrue = model.evaluate(x_KW, y_KW_ce)\n",
    "scoreFalse = model.evaluate(x_OOV, y_OOV_ce)\n",
    "\n",
    "print('\\nScore True of model with test KW dataset:', 100*scoreTrue[1],'%\\n')\n",
    "print('Score False of model with test OOV dataset:', 100*scoreFalse[1],'%\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
